# AI Persian VITS - Voice Synthesis & Cloning

Persian text-to-speech using VITS with two-phase training and voice cloning.

**Goal:** Train a Persian-optimized VITS model, then fine-tune it on individual voices for high-quality synthesis.

---

## ğŸ¯ What Is This Project?

**VITS** is a neural vocoder that generates speech from text. This implementation:
- Trains on multiple Persian datasets to learn Persian phonetics
- Fine-tunes on individual voices (10-60 seconds) for voice cloning
- Produces natural, expressive Persian speech

**Two-Phase Approach:**
1. **Phase 1 (One-time)**: Train base VITS model on Persian corpus â†’ `vits_persian_final.pth`
2. **Phase 2 (Per-voice)**: Fine-tune base model on individual speaker samples â†’ Voice clones

---

## ğŸ’» System Configuration

**Current Setup:**
- **Environment**: Conda (vits-env)
- **Python**: 3.11
- **PyTorch**: 2.10.0+cpu
- **Device**: CPU (20 cores)
- **Status**: âœ… Production Ready

**To Upgrade to GPU** (RTX 5070 Ti):
```powershell
pip install torch torchaudio torchvision --index-url https://download.pytorch.org/whl/cu121
```

---

## ğŸ“‚ Project Structure & File Purposes

```
ai-persian-vits/
â”‚
â”œâ”€â”€ ğŸ“‹ DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                 â† You are here (source of truth)
â”‚   â”œâ”€â”€ GETTINGSTARTED.md        â† Quick steps to get running
â”‚   â”œâ”€â”€ PRODUCTION_SETUP.md      â† Detailed setup guide
â”‚   â”œâ”€â”€ QUICK_START.md           â† Quick reference card
â”‚   â”œâ”€â”€ STATUS_REPORT.md         â† Deployment checklist
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md       â† Known issues & solutions
â”‚   â”œâ”€â”€ CUDA_SETUP.md            â† GPU configuration
â”‚   â””â”€â”€ COPILOT.md               â† AI assistant notes
â”‚
â”œâ”€â”€ ğŸ”§ SETUP & CONFIGURATION
â”‚   â”œâ”€â”€ setup-conda.ps1          â† First-time environment setup
â”‚   â”œâ”€â”€ activate-env.ps1         â† Daily environment launcher
â”‚   â”œâ”€â”€ environment.yml          â† Conda environment export
â”‚   â”œâ”€â”€ verify_setup.py          â† Verify all systems ready
â”‚   â”œâ”€â”€ requirements.txt          â† Pip dependencies (reference)
â”‚   â””â”€â”€ setup.sh                  â† Legacy bash setup
â”‚
â”œâ”€â”€ âš™ï¸ PREPROCESSING (Convert raw data â†’ training datasets)
â”‚   â”œâ”€â”€ preprocess_datasets.py   â† Main preprocessing script
â”‚   â”œâ”€â”€ audio_processor.py       â† Audio normalization & features
â”‚   â”œâ”€â”€ text_processor.py        â† Persian text normalization
â”‚   â””â”€â”€ README.md (in folder)    â† Dataset format docs
â”‚
â”œâ”€â”€ ğŸš‚ TRAINING (Phase 1: Train base VITS model)
â”‚   â”œâ”€â”€ train_vits.py            â† Main training script
â”‚   â”œâ”€â”€ train_vits.ps1           â† PowerShell trainer
â”‚   â”œâ”€â”€ train_vits.sh            â† Bash trainer
â”‚   â”œâ”€â”€ vits_config.json         â† Model architecture & hyperparams
â”‚   â””â”€â”€ README.md (in folder)    â† Training guide
â”‚
â”œâ”€â”€ ğŸ¤ FINETUNING (Phase 2: Clone individual voices)
â”‚   â”œâ”€â”€ finetune_voice.py        â† Fine-tuning script
â”‚   â”œâ”€â”€ finetune_voice.ps1       â† PowerShell fine-tuner
â”‚   â”œâ”€â”€ finetune_voice.sh        â† Bash fine-tuner
â”‚   â”œâ”€â”€ finetune_config.json     â† Fine-tuning hyperparams
â”‚   â””â”€â”€ README.md (in folder)    â† Fine-tuning guide
â”‚
â”œâ”€â”€ ğŸ”Š INFERENCE (Generate speech from text)
â”‚   â”œâ”€â”€ synthesize.py            â† Main inference script
â”‚   â”œâ”€â”€ synthesize.ps1           â† PowerShell synthesizer
â”‚   â”œâ”€â”€ synthesize.sh            â† Bash synthesizer
â”‚   â”œâ”€â”€ voice_encoder.py         â† Extract speaker embeddings
â”‚   â””â”€â”€ README.md (in folder)    â† Inference guide
â”‚
â”œâ”€â”€ ğŸ“¦ UTILITIES (Helper functions)
â”‚   â”œâ”€â”€ audio_utils.py           â† Audio I/O & processing
â”‚   â”œâ”€â”€ text_utils.py            â† Text processing & cleanup
â”‚   â”œâ”€â”€ file_utils.py            â† File operations
â”‚   â””â”€â”€ __init__.py              â† Module initialization
â”‚
â”œâ”€â”€ ğŸ“‚ DATA DIRECTORIES
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ raw/                 â† Place source datasets here
â”‚   â”‚   â”‚   â”œâ”€â”€ GPTInformal-Persian/
â”‚   â”‚   â”‚   â”œâ”€â”€ Mana-TTS/
â”‚   â”‚   â”‚   â”œâ”€â”€ ParsiGoo/
â”‚   â”‚   â”‚   â””â”€â”€ Quran-Persian/
â”‚   â”‚   â””â”€â”€ processed/           â† Created by preprocessing
â”‚   â”‚       â”œâ”€â”€ train.txt        â† Training data list
â”‚   â”‚       â”œâ”€â”€ val.txt          â† Validation data list
â”‚   â”‚       â”œâ”€â”€ metadata.txt     â† Audio metadata
â”‚   â”‚       â””â”€â”€ summary.json     â† Dataset statistics
â”‚   â”‚
â”‚   â”œâ”€â”€ checkpoints/             â† Saved models
â”‚   â”‚   â””â”€â”€ vits_persian_final.pth  â† Base model (Phase 1 output)
â”‚   â”‚
â”‚   â””â”€â”€ outputs/                 â† Training/inference outputs
â”‚       â”œâ”€â”€ logs/                â† TensorBoard event files
â”‚       â”œâ”€â”€ checkpoints/         â† Intermediate checkpoints
â”‚       â””â”€â”€ inference/           â† Generated audio samples
â”‚
â””â”€â”€ ğŸ³ CONTAINERIZATION
    â””â”€â”€ Dockerfile              â† Docker container definition
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ First-Time Setup (5 minutes)

```powershell
# Navigate to project
cd d:\Development\ai-persian-vits

# Create Conda environment with all dependencies
.\setup-conda.ps1

# Verify everything works
conda activate vits-env
python verify_setup.py
```

âœ… Output should show: CPU cores available, all packages installed.

### 2ï¸âƒ£ Prepare Data

Download Persian TTS datasets and place in `datasets/raw/`:
- [GPTInformal-Persian](https://huggingface.co/datasets/sinch/GPTInformal-Persian)
- [Mana-TTS](https://huggingface.co/datasets/persiannlp/mana-tts)
- [ParsiGoo](https://www.kaggle.com/datasets/matinkashefi/parsigoo-dataset)
- [Quran-Persian](https://github.com/persiannlp/quran)

Or use **dummy data** (for testing):
```powershell
conda activate vits-env
cd preprocessing
python preprocess_datasets.py --generate_dummy
```

### 3ï¸âƒ£ Preprocess Datasets (Phase 0)

Convert raw datasets to training format:
```powershell
conda activate vits-env
cd preprocessing
python preprocess_datasets.py --input_dir ../datasets/raw --output_dir ../datasets/processed
```

Creates:
- `train.txt` / `val.txt` - File lists with text & audio paths
- `metadata.txt` - Speaker info & statistics
- `summary.json` - Dataset overview

**Expect:** 10-30 minutes depending on data size.

### 4ï¸âƒ£ Train Base Model (Phase 1) - One Time Only

```powershell
conda activate vits-env
cd training
python train_vits.py --config vits_config.json --epochs 100
```

**Expect:**
- **CPU**: 2-8 hours per epoch (100+ epochs = weeks of training)
- **GPU**: 30 minutes per epoch (after CUDA install)
- **Output**: `checkpoints/vits_persian_final.pth`

**Monitor training:**
```powershell
# In another terminal
conda activate vits-env
tensorboard --logdir=outputs/logs
# Visit http://localhost:6006
```

### 5ï¸âƒ£ Fine-tune on Individual Voice (Phase 2)

Once you have a trained base model:

```powershell
conda activate vits-env
cd finetuning
python finetune_voice.py --config finetune_config.json --num_epochs 50
```

**Expect:** 30-60 minutes per voice on CPU.

### 6ï¸âƒ£ Generate Speech (Inference)

```powershell
conda activate vits-env
cd inference
python synthesize.py \
    --text "Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§" \
    --model_path ../checkpoints/vits_persian_final.pth \
    --output_path output.wav
```

**Expect:** < 1 second to generate speech.

---

## â±ï¸ Timeline Expectations

| Stage | Duration | Frequency |
|-------|----------|-----------|
| Setup | 5 minutes | Once |
| Preprocessing | 10-30 min | Once per dataset |
| Phase 1 (Training) | 2-8 hrs/epoch | Once (100+ epochs) |
| Phase 2 (Fine-tune) | 30-60 min | Once per voice |
| Inference | < 1 sec | Per sentence |

---

## ğŸ® Using Quick Launcher

Instead of manual activation, use:

```powershell
.\activate-env.ps1 verify       # Check setup
.\activate-env.ps1 train        # Start training
.\activate-env.ps1 preprocess   # Preprocess data
.\activate-env.ps1 infer        # Run inference
.\activate-env.ps1 finetune     # Fine-tune voice
.\activate-env.ps1 tensorboard  # Monitor training
.\activate-env.ps1 jupyter      # Launch notebook
```

---

## ğŸ“‹ Configuration Files

### `training/vits_config.json`
Controls:
- Model architecture (layers, hidden dims)
- Learning rate, batch size
- Number of epochs
- Audio preprocessing parameters

### `finetuning/finetune_config.json`
Controls:
- Fine-tuning learning rate (usually lower than training)
- Number of fine-tuning epochs
- Freeze which layers

---

## ğŸ”„ Workflow Summary

```
Raw Audio Data
    â†“
[Preprocessing] â†’ Normalized audio + text pairs
    â†“
[Phase 1: Training] â†’ Base VITS model (vits_persian_final.pth)
    â†“
[Phase 2: Fine-tuning] â†’ Voice-specific model
    â†“
[Inference] â†’ Persian speech synthesis
```

---

## ğŸ“š Full Documentation Files

| File | When to Read |
|------|--------------|
| **GETTINGSTARTED.md** | First thing - quick steps to run everything now |
| **README.md** | Now - full understanding of project (this file) |
| **PRODUCTION_SETUP.md** | Deep setup details, configuration options |
| **QUICK_START.md** | Quick reference during development |
| **STATUS_REPORT.md** | Deployment checklist, verification results |
| **TROUBLESHOOTING.md** | When something breaks |
| **CUDA_SETUP.md** | Only if upgrading to GPU |

---

## ğŸ› Common Issues

| Issue | Solution |
|-------|----------|
| PyTorch not found | Run `.\setup-conda.ps1` again |
| Out of memory | Reduce batch_size in config JSON |
| Out of disk space | Free up space or use smaller dataset |
| CUDA errors | Ignore if using CPU; skip CUDA_SETUP.md |
| Audio not loading | Check dataset format in preprocessing README |

See `TROUBLESHOOTING.md` for more.

---

## ğŸ”— Key Commands Reference

```powershell
# Setup
.\setup-conda.ps1                                    # One-time setup
conda activate vits-env                             # Activate environment
python verify_setup.py                              # Verify all systems

# Quick Launcher
.\activate-env.ps1 <command>                        # See options above

# Manual Commands
cd preprocessing; python preprocess_datasets.py     # Preprocess data
cd training; python train_vits.py                   # Train base model
cd finetuning; python finetune_voice.py            # Fine-tune voice
cd inference; python synthesize.py                  # Generate speech
tensorboard --logdir=outputs/logs                   # Monitor training
```

---

## ğŸ¯ One Year From Now

If you're returning to this project:

1. **Remember the goal**: Train Persian VITS â†’ Fine-tune on voices â†’ Synthesis
2. **Check status**: Run `python verify_setup.py` to ensure environment is ready
3. **Review structure**: This README explains every folder and file
4. **Start with**: `GETTINGSTARTED.md` for immediate steps
5. **Existing models**: Check `checkpoints/` for previously trained models
6. **Outputs**: Check `outputs/` for previous training logs and generated samples

---

## ğŸ“ Quick Help

- **Initial setup problems?** â†’ See `GETTINGSTARTED.md`
- **Want full details?** â†’ See `PRODUCTION_SETUP.md`
- **Quick reference?** â†’ See `QUICK_START.md`
- **Something broke?** â†’ See `TROUBLESHOOTING.md`
- **Need GPU?** â†’ See `CUDA_SETUP.md`

---

**Version**: 2.0 (Production Ready)  
**Last Updated**: February 2026  
**Device Mode**: CPU (GPU Ready)  
**Status**: âœ… Ready for Training
